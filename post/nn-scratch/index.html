<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.8.0"><meta name=author content="Eduardo Arnold"><meta name=description content="Understanding a bit of the math from neural nets and its implementation on Numpy.
"><link rel=alternate hreflang=en-us href=https://earnold.me/post/nn-scratch/><meta name=theme-color content="#2962ff"><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin=anonymous async></script>
<script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/css/academic.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_hu86725dfa3481f0beabea4a23db3db448_10764_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/images/icon_hu86725dfa3481f0beabea4a23db3db448_10764_192x192_fill_lanczos_center_3.png><link rel=canonical href=https://earnold.me/post/nn-scratch/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@eduardoarnoldh"><meta property="twitter:creator" content="@eduardoarnoldh"><meta property="og:site_name" content="Eduardo Arnold"><meta property="og:url" content="https://earnold.me/post/nn-scratch/"><meta property="og:title" content="Neural networks from scratch | Eduardo Arnold"><meta property="og:description" content="Understanding a bit of the math from neural nets and its implementation on Numpy.
"><meta property="og:image" content="https://earnold.me/images/icon_hu86725dfa3481f0beabea4a23db3db448_10764_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://earnold.me/images/icon_hu86725dfa3481f0beabea4a23db3db448_10764_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2017-04-12T12:00:00+00:00"><meta property="article:modified_time" content="2017-04-12T12:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://earnold.me/post/nn-scratch/"},"headline":"Neural networks from scratch","datePublished":"2017-04-12T12:00:00Z","dateModified":"2017-04-12T12:00:00Z","author":{"@type":"Person","name":"Eduardo Arnold"},"publisher":{"@type":"Organization","name":"Eduardo Arnold","logo":{"@type":"ImageObject","url":"https://earnold.me/images/icon_hu86725dfa3481f0beabea4a23db3db448_10764_192x192_fill_lanczos_center_3.png"}},"description":"Understanding a bit of the math from neural nets and its implementation on Numpy.\n"}</script><title>Neural networks from scratch | Eduardo Arnold</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Eduardo Arnold</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Eduardo Arnold</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"></ul></div></nav><article class=article><div class="article-container pt-3"><h1>Neural networks from scratch</h1><div class=article-metadata><span class=article-date>Apr 12, 2017</span>
<span class=middot-divider></span>
<span class=article-reading-time>11 min read</span></div></div><div class=article-container><div class=article-style><h2 id=introduction>Introduction</h2><p>I have used a handful of machine learning models in the past. These include simple linear regression models, support vector machines (SVMs) and neural networks. While working on different projects I was mostly concerned in solving a specific application problem and did not worry about the inner workings of the models I was using. I have delved into more details of SVM during my final undergraduate project but did not have the time to do the same for neural networks.</p><p>After reading and learning about it in more detail it has come the time for me to share it. In this post I will give some brief introduction to neural nets and derive some of the maths behind a simple architecture as well as its implementation using only
<a href=http://www.numpy.org/ target=_blank rel=noopener>Numpy</a>. I have based most of this post on
<a href=http://cs231n.github.io/neural-networks-case-study/ target=_blank rel=noopener>Stanford&rsquo;s CS231</a> notes which I found very useful for beginners. Some of the math derived here was not available there so it might be useful for a more interested reader.</p><p>Neural networks are organized in layers, each consisting of many units. These units are responsible for crunching the data. Each unit can receive many inputs but has a single output that can be connected to many more units in the following layer. In this study we will address a fully-connected structucture, meaning that every unit in a single layer receives input from all the units from the previous layer. To compute its output, each unit perform a weighted sum of its inputs and a bias term, then apply an activation funcion, in general non-linear, to the calculated sum. The model parameters consists of the connection weights between the units and their bias terms.</p><h2 id=defining-the-model>Defining the model</h2><p>To simplify our study we are going to use a two layer network architecture (the input layer is not counted). The input layer $x$ has $N_x$ units, the hidden layer $h$ has $N_h$ and the output layer $y$ has $N_y$ units.</p><p>We could specify this architecture to perform multi-class classification, so the output layer would give the probability the sample belongs to each of the available classes. In this case we use $N_y$ as the number of classes and to enforce a probabilistic output we use an activation function called <strong>softmax</strong> on the output layer, which also guarantess that the sum of the classes probabilities sums to 1.</p><p>As for the hidden layer we can use a <strong>RELU</strong> activation function, because it is avery simple to evaluate non-linear function: $\text{RELU}(z) = \max(0, z)$. There are other reasons why we would use it, mostly to avoid a problem called vanishing gradient, but in a shallow network such as this one this would not be a problem.</p><p>We define the weights of the connections between the input and hidden layer units as the matrix $W1 \in \mathbb{R}^{N_x \times N_h}$, where $W1_{i,j}$ is the weight of the connection between the $i$-th input layer unit to the $j$-th hidden layer unit. The bias vector of the hidden layer is defined as $b1 \in \mathbb{R}^{N_h}$. Similarly we have the parameters of connection between the hidden layer to the output layer: $W2 \in \mathbb{R}^{N_h \times N_y}$ and $b2 \in \mathbb{R}^{N_y}.$</p><p><img src=/notebooks/nn-diagram.png alt=nn-diagram></p><h2 id=forward-propagation>Forward propagation</h2><p>Assuming we have all the ideal model parameters $W1, W2, b1, b2$, how do we get the output of the network for a given input sample? This is called forward propagation, since the data flows from the input layer, through the hidden layers and finally to the output layer as presented in the following equations.</p><p>$$\begin{align*} \\
h &= \max(0,x W1 + b1) \\
y &= \text{softmax}(\underbrace{h W2 + b2}_\textrm{score})
\end{align*}$$</p><p>The <strong>softmax</strong> activation function can be expressed as
$$ \text{softmax}(z)_j = \frac{e^{z_j}}{\sum_{i=0}^{N_z}e^{z_i}} $$</p><p>This formulation allows the input $x$ to have many samples, each in a row, so $x \in \mathbb{R}^{n \times N_\text{features}}$, where $n$ is the number of samples in a batch, also called batch size, and $N_\text{features}$ is the number of features, or the dimension of each sample. This would yield an output $y \in \mathbb{R}^{n \times N_y}$, where each sample probability distribution among classes is given in a row.</p><h2 id=training-process>Training process</h2><p>In order to get the ideal model parameters we have to train the network on a training set. This consists of an optimization process where we try to minimize a loss function that tells how close the network output $y$ is to the real labels $\hat{y}$. At each iteration of this process we obtain new values for the parameters that will hopefully decrease the value of the loss function.</p><p>In this example, since we assumed a multi-class classification problem with a probabilistic output, the ideal loss function to use is the categorical cross-entropy function, given by
$$ L_i = -\log y_{\hat{y}_i}$$</p><p>To make sense of this function we can analyse its behaviour. For a given sample $x_i$ belonging to class $\hat{y}_i$ it will compute the negative log of the output probability of the sample belonging to classs $\hat{y}_i$ (given by the $\hat{y}_i$-th component of $y$). Ideally this probability would be 1, which would make $L_i=0$. Whenever this is not the case, there is a loss associated with the sample $x_i$.</p><p>Now we have a measure to evaluate how good our classifier is doing on the training set we can try to optimize the network parameters to get the loss as close to zero as possible. We do this using an iterative algorithm called <strong>Stochastic Gradient Descent</strong>. To give a brief overview of this method, assume all network parameters are represented in a vector $\theta$. We can compute the variation of the loss function $\Delta L$ given a variation of the parameters vector $\Delta \theta$ as $$\Delta L = \Delta \theta \cdot \nabla L$$ where $\nabla L$ is the gradient of the loss with respect to the parameters $\theta$. We always want to descrease the loss, so we want $\Delta L &lt; 0$. One way to guarantee this condition is to choose the variation of parameters as $$\Delta \theta = - \eta \nabla L$$ for a small-enough learning rate $\eta >0$, which would yield $$\Delta L = -\eta |\nabla L|^2.$$</p><p>This description is for vanilla Gradient Descent, also called batch-GD (where $L = \sum L_i$), so every sample is considered in the gradient. The stochastic part comes when you only consider a single sample at each iteration step, what reduces training time, especially on big datasets. Although it may seem attractive, this method offers slower convergence since there is a lot of zig-zagging between samples optimizations. To overcome this another variation called mini-batch GD can be used. This method lies in between batch-GD (uses one sample) and SGD (uses all samples), since it considers a mini-batch of size $N_b$ to compute the gradient, thus reducing training time and still allowing faster convergence.</p><p>By iteratively running this optimization algorithm we can reduce the loss function and train our model. There is one missing step though: how to compute the loss function gradient $\nabla L.$</p><h2 id=backpropagation-and-gradient-computation>Backpropagation and gradient computation</h2><p>Even considering our small network the loss is a rather complex function of the network parameters given all multiplications and non-linear activations. To compute its gradient $\nabla L$ we must find the derivative of $L$ with respect to all model parameters, which can be difficult to be done analytically. We then use an algorithm called Backpropagation, which is basically the use of calculus&rsquo; chain-rule. By multiplying the local derivatives from layer to layer we can numerically evaluate the derivative of the loss with respect to any parameter.</p><p>We start from the output layer $y$. Since $$ L_i = -\log y_{\hat{y}_i}$$ we have $$\frac{\partial L_i}{\partial y_k} = \frac{-1}{y_k} 1(\hat{y}_i=k)$$ where 1(z) is the indicator function (1 if argument true, otherwise 0).</p><p>$\DeclareMathOperator{\score}{score}$
We then calculate the derivatives of the output $y_k$ with respect the intermediate variable $\score = h W2 + b2$, with $ y = \text{softmax}(h W2 + b2)$. We must consider two cases, one for the derivative of $y_k$ with respect to $\score_j$ with $k \neq j$ and another with $k=j$.</p><p>For the first case we can write $$ y_k = \frac{e^{\score_k}}{e^{\score_j} + \sum_{i \neq j} e^{\score_i}}$$ then using the quotient rule for derivatives we have:
$$\frac{\partial y_k}{\partial \text{score}_j} = \frac{-e^{\score_k}e^{\score_j}}{(\sum_i e^{\score_i})^2} = -\frac{e^{\score_k}}{\sum_i e^{\score_i}} \frac{e^{\score_j}}{\sum_i e^{\score_i}} = -y_k y_j$$</p><p>For the second case, when $k=j$ we can write $$ y_k = \frac{e^{\score_k}}{e^{\score_k} + \sum_{i \neq k} e^{\score_i}}$$ and then the derivative becomes:</p><div>\begin{eqnarray}
\frac{\partial y_k}{\partial \text{score}_k} &=& \frac{e^{\score_k}(\sum_i e^{\score_i}) - e^{2\score_k}}{(\sum_i e^{\score_i})^2} \\
&=& \frac{e^{\score_k}}{\sum_i e^{\score_i}} - \frac{e^{\score_k}}{\sum_i e^{\score_i}} \frac{e^{\score_k}}{\sum_i e^{\score_i}} \\
&=&  y_k-y_k y_k \\
 &=& y_k(1-y_k)
\end{eqnarray}</div><p>Now, to calculate the derivative of the loss with respect to the score intermediate variables we use the chain-rule as follows:</p><div>\begin{eqnarray}
\frac{\partial L_i}{\partial \score_j} & = & \frac{\partial L_i}{\partial y_k} \frac{\partial y_k}{\partial \score_j} &\\
   & = & \frac{-1}{y_{\hat{y}_i}} \times -y_{\hat{y}_i} y_j = y_j, &\text{ if } j \neq \hat{y}_i \\
  & = & \frac{-1}{y_{\hat{y}_i}} \times y_{\hat{y}_i}(1-y_{\hat{y}_i}) = y_{\hat{y}_i} -1, &\text{ if } j=\hat{y}_i
\end{eqnarray}</div><p>For implementation reasons we can call a vector $\text{dscore} \in \mathbb{R}^{N_y}$ where each component is the derivative of the loss regarding a component of the score variable. In a compact form: $$ \text{dscore}_j = \frac{\partial L_i}{\partial \score_j} = y_j - 1(j=\hat{y}_i)$$</p><p>We must now propagate this derivative to the parameters of the output layer. From definition we have $\score = h W2 + b2$. To improve visualization we can expand it in the form (considering a single sample batch, n=1):</p><p>$$\begin{align*}
\score_1 &= h_1 W2_{11} + h_2 W2_{21} + h_3 W2_{31} + \cdots + b2_1 \\
\score_2 &= h_1 W2_{12} + h_2 W2_{22} + h_3 W2_{32} + \cdots + b2_2 \\
\score_3 &= h_1 W2_{13} + h_2 W2_{23} + h_3 W2_{33} + \cdots + b2_3 \\
& \vdots & \\
\score_j &= h_1 W2_{1j} + h_2 W2_{2j} + h_3 W2_{3j} + \cdots + b2_j \\
\end{align*}$$</p><p>It is easy to see that $$\frac{\partial \score_j}{\partial b2_j} = 1 \implies \frac{\partial L_i}{\partial b2_j} = \frac{\partial L_i}{\partial \score_j} \frac{\partial \score_j}{\partial b2_j} = \frac{\partial L_i}{\partial \score_j}.$$ This imples that the vector of weights update for $b2$ is $db2 = \text{dscore}$</p><p>Similarly, we have $$ \frac{\partial \score_j}{\partial W2_{kj}} = h_k \implies \frac{\partial L_i}{\partial W2_{kj}} = \frac{\partial L_i}{\partial \score_j} \frac{\partial \score_j}{\partial W2_{kj}} = h_k \frac{\partial L_i}{\partial \score_j}$$</p><p>In this case, the matrix of weights updates is given by</p><p>$$\begin{align*}
dW2 &= \begin{pmatrix} \
\frac{\partial L}{\partial W_{11}} & \frac{\partial L}{\partial W_{12}} & \cdots \\
\frac{\partial L}{\partial W_{21}} & \frac{\partial L}{\partial W_{22}} & \cdots \\
\vdots & \vdots & \ddots \\
\end{pmatrix} \\
&= \begin{pmatrix} \
h_1 \text{dscore}_1 & h_1 \text{dscore}_2 & \cdots \\
h_2 \text{dscore}_1 & h_2 \text{dscore}_2 & \cdots \\
\vdots & \vdots & \ddots \\
\end{pmatrix} \\
& = \begin{pmatrix} \
h_1 \\
h_2 \\
\vdots \\
\end{pmatrix} \
\begin{pmatrix} \
\text{dscore}_1 & \text{dscore}_2 & \cdots \\
\end{pmatrix} \\
& = h^T \text{dscore} \\
\end{align*}$$</p><p>To propagate the gradient to the hidden layer we must first calculate the gradient with respect to $h$: $$\frac{\partial \score_j}{\partial h_k} = W2_{kj}$$</p><p>The differential parameter vector $dh$ is given by:</p><p>$$\begin{align*}
dh^T &= \begin{pmatrix} \
\frac{\partial L}{\partial h_1} \\
\frac{\partial L}{\partial h_2} \\
\vdots \\
\end{pmatrix} \\
&= \begin{pmatrix} \
\frac{\partial L}{\partial\score_1}\frac{\partial \score_1}{\partial h_1}+ \frac{\partial L}{\partial\score_2}\frac{\partial \score_2}{\partial h_1} + \cdots\\
\frac{\partial L}{\partial\score_1}\frac{\partial \score_1}{\partial h_2}+ \frac{\partial L}{\partial\score_2}\frac{\partial \score_2}{\partial h_2} + \cdots\\
\vdots \\
\end{pmatrix}\\
&= \begin{pmatrix} \
\frac{\partial \score_1}{\partial h_1} & \frac{\partial \score_2}{\partial h_1} & \cdots\\
\frac{\partial \score_1}{\partial h_2} & \frac{\partial \score_2}{\partial h_2} & \cdots\\
\vdots & \vdots & \ddots \\
\end{pmatrix} \
\begin{pmatrix} \
\frac{\partial L}{\partial\score_1}\\
\frac{\partial L}{\partial\score_2}\\
\vdots \\
\end{pmatrix} \\
&= W2 \times \text{dscore}^T\\
dh &= \text{dscore} \times W2^T \\
\end{align*}$$</p><p>Next we consider the RELU activation: $h=max(0, \underbrace{xW1+b1}_\textrm{r})$. $\frac{dh}{dr} = 1(r>0)$. Thus, $dr = dh \times 1(h>0)$.</p><p>Finally, for the hidden layer, we can observe $dh$ as the output and $x$ as input, so by extending the equations for $dW2$ and $db2$ we have</p><div>$$\begin{align*}
dW1 &= x^T \text{dr} \\
  db1 &= \text{dr}
\end{align*}$$</div><h2 id=numpy-implementation>Numpy implementation</h2><p>The forward propagation is straightforward as can be seen below.</p><pre><code class=language-python>h = np.maximum(0, np.dot(x,W1)+b1)
score = np.dot(h,W2)+b2
y = np.exp(score)
y /= np.sum(y, axis=1, keepdims=True)
</code></pre><p>Although understanding backpropagation can be difficult, the resulting equations are somewhat simple to implement, because they only need to consider the local derivatives at each step.</p><p>Primarily we computer the $\text{dscore}$ intermediate variable, where y_t represents $\hat{y}$, the true class label.</p><pre><code class=language-python>dscore = np.copy(y)
dscore[range(n), y_t] -= 1
dscore /= n
</code></pre><p>Next the output layer parameters updates are calculated. Since we now have $n$ training samples, we have $L = \frac{1}{n} \sum_{i=0}^n L_i$, so dscore gets summed (the division by $n$ has already taken place in the previous step).</p><pre><code class=language-python>dW2 = np.dot(h.T, dscore)
db2 = np.sum(dscore, axis=0, keepdims=True)
</code></pre><p>The hidden layer activation derivative is calculated, followed by the parameter updates.</p><pre><code class=language-python>dh = np.dot(dscore, W2.T)
dr = dh
dr[h &lt;= 0] = 0

dW1 = np.dot(x.T, dr)
db1 = np.sum(dr, axis=0, keepdims=True)
</code></pre><p>Finally we apply the weight updates using the a specified learning rate $\eta$ (lr).</p><pre><code class=language-python>W1 -= lr*dW1
b1 -= lr*db1
W2 -= lr*dW2
b2 -= lr*db2
</code></pre><h2 id=source-code>Source code</h2><p>To check the code and results, please visit
<a href=/notebooks/nn-scratch.html>this notebook</a>.</p></div><div class=article-tags><a class="badge badge-light" href=/tag/machine-learning/>machine learning</a>
<a class="badge badge-light" href=/tag/deep-learning/>deep learning</a></div><div class="media author-card content-widget-hr"><img class="avatar mr-3 avatar-circle" src=/author/eduardo-arnold/avatar_hu0560068c008c418db3fb9e5dbdd74d76_96460_270x270_fill_q90_lanczos_center.jpg alt="Eduardo Arnold"><div class=media-body><h5 class=card-title><a href=https://earnold.me/>Eduardo Arnold</a></h5><h6 class=card-subtitle>Machine Learning Engineer</h6><p class=card-text>I&rsquo;m a Machine Learning Engineer at Niantic. Previously, I obtained my PhD degree at the University of Warwick, supervised by Mehrdad Dianati and Paul Jennings, and focusing on perception methods for autonomous driving.</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/eduardoarnoldh target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?user=AEHGoAkAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/eduardohenriquearnold target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://linkedin.com/in/eduardohenriquearnold target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li></ul></div></div><div class="article-widget content-widget-hr"><h3>Related</h3><ul><li><a href=/post/dogsvscats/>What I have learnt from dogs and cats</a></li></ul></div></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js></script>
<script>const code_highlighting=!0</script><script>const isSiteThemeDark=!1</script><script src=/js/academic.min.a0f52cd61d0242fd8ed5d785d9bff037.js></script><div class=container><footer class=site-footer><p class=powered-by></p><p class=powered-by>Powered by the
<a href=https://sourcethemes.com/academic/ target=_blank rel=noopener>Academic theme</a> for
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>.
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div></body></html>